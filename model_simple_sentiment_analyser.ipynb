{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc8c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # avoid slide-copy-warning \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b1a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CONFIGURATION = {\n",
    "    \"path\"     : \"data/train.csv\",\n",
    "    \"columns\"  : [\"label\", \"ids\", \"date\", \"flag\", \"user\", \"text\"],\n",
    "    \"encoding\" : \"ISO-8859-1\",\n",
    "    \"test_size\": 0.2,\n",
    "}\n",
    "\n",
    "SAMPLE_SIZE = 200000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34416ba2",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed35b8",
   "metadata": {},
   "source": [
    "The data is arranged as follows\n",
    "    \n",
    "- *label*: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)<br>\n",
    "- *ids*: The id of the tweet (2087)<br>\n",
    "- *date*: the date of the tweet (Sat May 16 23:58:44 UTC 2009)<br>\n",
    "- *flag*: The query (lyx). If there is no query, then this value is NO_QUERY.<br>\n",
    "- *user*: the user that tweeted (robotickilldozr)<br>\n",
    "- *text*: the text of the tweet (Lyx is cool)<br>\n",
    "\n",
    "You can find and download the data from [here](https://www.kaggle.com/datasets/kazanova/sentiment140)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9368dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(DATASET_CONFIGURATION[\"path\"], \n",
    "                encoding=DATASET_CONFIGURATION[\"encoding\"], \n",
    "                   names=DATASET_CONFIGURATION[\"columns\"])\n",
    "\n",
    "sampled_data = data_frame.sample(n=SAMPLE_SIZE, random_state=42) # sampling because my computer is slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4249e27",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52371091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(sampled_data, test_size=DATASET_CONFIGURATION[\"test_size\"], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e117f",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5b1e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447515</th>\n",
       "      <td>@biglime same  I googled it and its the same f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119902</th>\n",
       "      <td>@stinamfking I remembered. I think. Penny Lane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19368</th>\n",
       "      <td>i am depressed again. i miss home so much rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468176</th>\n",
       "      <td>@andrewjennings i think someones excited about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048930</th>\n",
       "      <td>@greggarbo One of my favorite songs.  australi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114266</th>\n",
       "      <td>@samanthai Awww *blush* Thanks!! You are a god...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408466</th>\n",
       "      <td>@therealTiffany awe, I'm sorry  I hope you fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522785</th>\n",
       "      <td>@AureliusTjin  Haha, yeah. Your name is very u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387960</th>\n",
       "      <td>i need money for tickets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472226</th>\n",
       "      <td>@stevem4y I need DJ lessons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "447515   @biglime same  I googled it and its the same f...\n",
       "1119902  @stinamfking I remembered. I think. Penny Lane...\n",
       "19368     i am depressed again. i miss home so much rig...\n",
       "1468176  @andrewjennings i think someones excited about...\n",
       "1048930  @greggarbo One of my favorite songs.  australi...\n",
       "...                                                    ...\n",
       "1114266  @samanthai Awww *blush* Thanks!! You are a god...\n",
       "408466   @therealTiffany awe, I'm sorry  I hope you fee...\n",
       "1522785  @AureliusTjin  Haha, yeah. Your name is very u...\n",
       "387960                           i need money for tickets \n",
       "472226                        @stevem4y I need DJ lessons \n",
       "\n",
       "[160000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = data_train['label']\n",
    "\n",
    "columns_to_drop = ['label', 'ids', 'date', 'flag', 'user']\n",
    "data_train = data_train.drop(columns=columns_to_drop)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a7cc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447515</th>\n",
       "      <td>biglim googl everyon probli jst isnt yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119902</th>\n",
       "      <td>stinamfk rememb . think . penni lane ! that sf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19368</th>\n",
       "      <td>depress . miss home much right !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468176</th>\n",
       "      <td>andrewjen think someon excit toni ! !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048930</th>\n",
       "      <td>greggarbo one favorit song . australiagameshol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "447515            biglim googl everyon probli jst isnt yet\n",
       "1119902  stinamfk rememb . think . penni lane ! that sf...\n",
       "19368                     depress . miss home much right !\n",
       "1468176              andrewjen think someon excit toni ! !\n",
       "1048930  greggarbo one favorit song . australiagameshol..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data_train['text']\n",
    "\n",
    "punctuation = ['!', '.']\n",
    "\n",
    "def clean_text_with_punctuation(text):\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(f'Expected input of type str, got {type(text)}')\n",
    "        \n",
    "    processed_chars = []\n",
    "    \n",
    "    for char in text:\n",
    "        if char.isalnum() or char.isspace() or char in punctuation:\n",
    "            processed_chars.append(char)\n",
    "            \n",
    "        else: processed_chars.append('')\n",
    "\n",
    "    cleaned_text = ''.join(processed_chars)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    filtered_tokens = []\n",
    "    for word in tokens:\n",
    "        if word not in stop_words:\n",
    "            filtered_tokens.append(word)\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stem(tokens):\n",
    "    stemmed_tokens = []\n",
    "    for word in tokens:\n",
    "        stemmed_tokens.append(stemmer.stem(word))\n",
    "    \n",
    "    return stemmed_tokens\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(f'Expected input of type str, got {type(text)}')\n",
    "        \n",
    "    text       = text.lower()\n",
    "    clean_text = clean_text_with_punctuation(text)\n",
    "    \n",
    "    # print(f'Clean text: {clean_text}')\n",
    "    \n",
    "    tokens         = tokenize(clean_text)\n",
    "    stemmed_tokens = stem(tokens)\n",
    "    \n",
    "    final_clean_text = ' '.join(stemmed_tokens)\n",
    "\n",
    "    return final_clean_text\n",
    "\n",
    "data_train['text'] = texts.apply(preprocess_text)\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea1203",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f58716",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train['text']\n",
    "\n",
    "data_test['text'] = data_test['text'].apply(preprocess_text)\n",
    "\n",
    "X_test = data_test['text']\n",
    "y_test = data_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ea4759f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'multinomialnb__alpha': 1.0, 'tfidfvectorizer__max_features': 3000, 'tfidfvectorizer__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(max_features=3000, ngram_range=(1, 2))),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "parameter_candidates  = {\n",
    "    'tfidfvectorizer__max_features': [2000, 2500, 3000],       # maximum number of unique words\n",
    "    'tfidfvectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)],  # range of n-grams (contiguous sequences of words)\n",
    "    'multinomialnb__alpha': [0.1, 0.5, 1.0]                    # smoothing parameter in the classifier\n",
    "}\n",
    "\n",
    "# find the best hyperparameters\n",
    "grid_search = GridSearchCV(pipeline, parameter_candidates , n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_hyperparams = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_hyperparams)\n",
    "\n",
    "# create the final model\n",
    "final_model = make_pipeline(\n",
    "    TfidfVectorizer(max_features=best_hyperparams['tfidfvectorizer__max_features'],\n",
    "                     ngram_range=best_hyperparams['tfidfvectorizer__ngram_range']),\n",
    "             MultinomialNB(alpha=best_hyperparams['multinomialnb__alpha'])\n",
    ")\n",
    "\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd001d",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "034ff29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(final_model, 'final_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8216e",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a38282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.758225\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76     20088\n",
      "           4       0.75      0.77      0.76     19912\n",
      "\n",
      "    accuracy                           0.76     40000\n",
      "   macro avg       0.76      0.76      0.76     40000\n",
      "weighted avg       0.76      0.76      0.76     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred   = final_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report   = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:\\n', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b4afec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Score: 0.75475\n",
      "Fold 2 Score: 0.7561875\n",
      "Fold 3 Score: 0.754\n",
      "Fold 4 Score: 0.75578125\n",
      "Fold 5 Score: 0.75309375\n",
      "Mean Cross-Validation Score: 0.7547625000000001\n",
      "Standard Deviation of Scores: 0.0011344395642783204\n"
     ]
    }
   ],
   "source": [
    "# perform cross-validation with 5 folds\n",
    "scores = cross_val_score(final_model, X_train, y_train, cv=5)\n",
    "\n",
    "for i, score in enumerate(scores, 1):\n",
    "    print(f'Fold {i} Score: {score}')\n",
    "\n",
    "mean_score = scores.mean()\n",
    "std_dev    = scores.std()\n",
    "print(f'Mean Cross-Validation Score: {mean_score}')\n",
    "print(f'Standard Deviation of Scores: {std_dev}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
